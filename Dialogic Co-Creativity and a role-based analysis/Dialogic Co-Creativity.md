New technologies often bring new creative possibilities, resistance and open questions. 
For example, the camera was initially met with resistance. The french poet baudeliere called it the refuge of ill endowned painters (cite). 
Similarly, the electronic synthetiser was met with resistance and questions about its value as a creative tool (cite). A ban was considered and it faces resistance by many in the music industry (cite). 
However, both of these tools have now evolved mature communities of practice, and have yielded new artforms on their own, like photography, film, and electronic music.
Some claim generative artificial intelligence will follow a similar arc: an initial period of resistance, followed by a consolidation period where practiotioners develop effective ways to use it in existing and new creative processes. 
However, an important consideration in this extrapolation is that generative artificial intelligence is qualitiatively a different technology from the previously mentioned. 
In particular, the fact that it has an increased level of creative agency. 
They are capable of producing full creative outputs with limited user input, such as images, text, music and other videos. 
Capabilities have grown fast. Recent research has shown that some of these generative AI systems like large language models now outperform humans in tests of creativity such as the alternative use test (cite). Another study found poetry written by a language model was preferred and demmed more creative than that produced by humans (cite). In the case of images, generative systems are able to now produce outputs that are undistinguishable from that made of humans, including photographs and art (cite).A recent large scale study showed that often people preferred art generated using a genAI model when they didn't know it was generated by it. Indeed, there is an increasing empirical literature that questions the notion that creativity is exclusive to humans, and that it can be exhibited by artificial intelligence models at least when measured with similar metrics used for humans including novelty, value, lateral thinking, subjectively rated beauty, among others. 
This all suggests that a reconfiguration of our relationship to these tools in creative activities is warranted. 
The notion of co-creativity offers one such a configuration. 
An interaction where creativity is brough by the two parts to create a common artifact. 
Candy initially defined co-creativity in human collaborations as: 
She then developed the same notion for the case of human machine interactions. 
Davis introduced human-Ai co-creativity. 
A large part of this literature was developed pre-generative AI, however it did consider the possibility of future creative machines. 
More recently, the literature on co-creativity has grown driven by the rise in generative Ai capabilities. 
Kantosalo, Rezwana, and others have developed the notion of co-creativity. 
In this thesis, I argue that a co-creative lens if useful to design effective human-Ai interactions in creative activities, and I use it as a conceptual foundation. 
However, I introduce a second concept to this conceptual framing. 
Dialogic interaction. 
Rooted in dialogue. 
Understand an interaction as a cycle of mutual influence. 
There is a rich tradition in practitioners understanding their engagement with their tools as a dialogue, where they get influenced by the affordances and behavior of their tools, and the tool, gets influenced by the direct action and manipulation by the user. 
I argue dialogue, and dialogic interaction, coupled with co-creativity, offers a robust foundation to reconfigure our relationship to machines in creative activities when generative Ai capabilities are involved. 

## Dialogic co-creativity
In this section I will outline concepts from the philosophy and theory of dialogue that are useful to build a model for human machine co-creativity. 
Socratic dialogue: rather than a unilateral exposition, a dialogue where interlocutors question each other to arrive at the solution of a philosophical problem. 
As such it is also iniherently creative as it creates a new idea that is both novel and  valuable. 

Bohm introduces a similar concept of dialogue being inherently creative. 
For him, a crucial component of dialogue is that it serves to align meaning. It starts with the idea that two or more interlocutors have different world models, which determine assign meanings, and through dialogue, they learn to align these models and thus arrive at common meanings. 
This is important in human-Ai interaction particularly because of the notion of latent spaces. 
Models learn to build world models based on the data they are provided, and generate a latent space that is by definition hidden from humans. This latent spaces is made by a compressed representation of higher dimensional artifacts such as images or text, and their structure determines how and what the model generates. This inscrutability makes the model less explainable and controlled generation by the user more difficult. Indeed, the slot-machine nature of generative systems has been recognised as a key limitation to their meaningful adoption. A process of dialogues can help users form a mental model of the AI's own world model, and viceversa, such that meanings are aligned and generation becomes more relevant and controlled. 

Buber dialogue: I-it, I-thou. Considers dialogue with non-human entities. Subject-subject. Boundaries are blurred between subjects. This is reminiscent of flow, a key components of creative success when boundaries between the subject, the activity and the tool is blurred. Subject-subject vs subject-object. 

Bakhtin: unifnishedness, iterative. Meaning making. 

Hayes and Reddy (1983) on the characteristics for "gracefully interacting systems". Heddy and Reddy claim that “it is very important for
a gracefully interacting system to conduct a dialogue in as human-like a way as possible”. Repair. 

Suchman: human-machine reconfigurations. Greater reactivity, interactivity and purposeful behavior. 

Suchman, Frankel: defining roles and the use case as important to understand how the dialogue is structured. 

Cybernetics: Wiener, control and communication. Feedback as a key way to characterise systems. To understand a system is needed to understand their feedback dynamics. I take this to understand the case of a human-machine system, and characterise it by its dynamics. 

Gordon Pask: conversation theory. 

More recently, work on HCI, mixed initiative, characterises human-machine creative interactions as dialogues. 
Muller: conversation. 

Bown. Dialogic interaction or creative dialogue for the case of AI systems. I co-developed this. 

Offers three levels of dialogue. Pseudo, weak assymetric, full dialogue. 
I use this levels to then build three levels of co-creativity, based on the characteristics above. 

I provide table explaining the elements I draw from:

TABLE. 

## Classification levels of co-creativity

Largely expands on types of dialogue. Uses that framing. 
In what sense does it use that framing? 
In the sense that it is classified based on the amount of feedback loops, mutual influence, communication. It is a dialogic lens to classify levels of co-creativity. 
It doesn't mean one is better than the other. But it does say one enabled a dialogue more. 

Scale based on the level of dialogue. Why don't I just use the type of dialogue? This is a more granular classification. I think the three levels leave out important distinctions. 

### Level 1: pure generators

Guided explorations of the latent space. This can be either through language, traversing 2D attribute spaces, twisting knobs and sliders, etc. 
A crucial argument I make is that maybe text is not even the best interface in this case. It doesn't mean they are super limited. They may be useful in many situations. Pure divergence and exploration. 

MusicFX Dj fits here. Guided exploration of latent space, but no output as input feedback loops. Perhaps you don't need it. 

Theres mutual influence but limited. It might elicit the user to rethink goals and rediscover new directions.

Examples include
Simple generators. 

Roles:
Exploratory.
Divergent.
Inspiration.

Example systems:
first generation text-to-image
DiscoDiffusion
Dalle 2
GANs
VAEs?
New media. 

### Level 2: iterative generators
Defining quality? 
There is a greater degree of feedback. More complete. An output can become an input for further iteration. 
Users can bring their own images as reference. 
Why is this different than generation? 
Greater control and influence. 
Users can meaningfully bring their aesthetic preferences. 
Either with image references, or style references. 
-Challenges:
Consistency across iterations. 
Control. 


Limitation: 
User and AI dont engage in a two way communication. Merely it is through requests. User cannot communicate goals, discuss, clarify, etc. 

Roles: 
Design imaginator. 

Use cases: generate a design
generate photos of a person in given situation (modelling, fashion, storytelling)

### Level 3: Communicative co-creator
Defining quality: 
Two way communication (should this be reserved for four?) Rezwana and Maher.
Something like chatgpt currently. It uses tools, triggers actions. 
Can push back on the user. Explicitely makes user rethink perspective. Question, give feedback, constructuvely critique. 

Limitation:
The system might respond and try to align and model user, but generation and communication are not fully integrated. 
We dont share a common workspace and common actions on the creation. 

### Level 4: Full co-creator
defining quality
Two way communication. 
Shared creative workspace, communication and generation are fully integrated. 

Something like Common AI
ChatGPT with Canvas
Claude with artefacts

Local coherence. 
No project embededness. 
The coherence is ephemeral. You might need to realign. 
ChatGPT with memory and Claude projects moves in this direction. 

### Level 5: Fully-embedded co-creator

Two way communication
Shared creative workspace
Pushes back 
Has history, learns user preference

Defining characteristic: 
It is embedded within the user's creative workspace and world. For example, 
Has access to rich and necessary context of users work, preferences, history. 

Example: cursor. It is within the users code base. 
A writer that has access to the writers manuscripts, and is embedded within 

This one truly enhances users cognitive processes. For example, it can be connected to a knowledge systems, making new connections for the user. 

Levels of co-creativity
Linked to Ollie's three levels. 

Level 1 and 2: pseudo-dialogue
Level 3: weak assymetrical dialogue
Level 4 and 5: full dialogue 


As next steps: 
I can categorise a bunch on tools according to this. This will be fun and useful!
Use the role based papers to categorise them as such. 

In final chapter I summarise and discuss everything. 

Discussion: 5 is not better than 1 in every case! There are tradeoffs. Sometimes you want to prioritise exploratory dynamics, not convergent ones. You don't eed the whole infrastructure baggage that comes with desinging a fully-embedded co-creator. 

In this chapter I will develop the following arguments: 

The way creatives engage with their tools can be understood as a dialogue.
New capabilities of generative AI warrant a reconceptualisation of our relationship to machines, particularly in creative contexts. 
Using dialogic interaction is a useful framing for this. 
We can understand our relationship to generative models as co-creativity. Is this the case in every interaction? 
In what situations it is not a co-creation? 
Can it always be understood as co-creation? 
Well, how do we define co-creation. 

Interacting with a system that has creativity. 
Well what is creativity: ability to produce novel and valuable artifacts. 
Largely, systems display those capabilities. 
Does a tool enable co-creativity? 
No. 
Is it a dialogue? 
Yes. 
What is a dialogue? 
An interaction between subjects where mutual influence happens and that is inherently creative. Alignment of meaning happens. 
Can a tool do this. To a certain degree. 
There is mutual influence, but there is no alignment on meaning. 
There is no discussion about goals, no alignment of meaning. 
But there is mutual influence? 
Yes. 
So this means there are multiple levels of dialogue? 
Yes
How can we classify them? 
Bown and Me (secondary coauthor). 
Pseudodialogue. 
Weak assymetric dialogue. 
Full dialogue.
Do all generative systems show full dialogue? 
No. Does ChatGPT do it? 
Sort of. 
Does Leonardo do it. 
No. 
Does MJ do it? 
No.
Is that a bad thing? 
Not necessarily. It depends what you using it for, what part of the creative process it is assuming, and what role we give it. 
Well, what are those roles? What are those use cases?
Well, I don't know. 
This is what I examine in my thesis. That's why I played around with different technologies.
Ok, but how might different roles related to different levels of dialogue? 
Well, I don't know, this is what I examine in my thesis. 
In what ways can they be related? 
For example, if I want to use a tool to merely ideate and stimulate divergent thinking, I probably don't need full dialogue. I only want to generate many concepts, guided by something (what is this something?) But I do not need to enable a feedback loop, or mantain consistency. I am thinking about the design use case where you generate ideas. This is probably pseudodialogue.
Another example: if I want to use a tool to generate images for a magazine, I want to converge, therefore I do want to refine, enable consistency and iteration (feedback dynamics). This is probably weak assymetric dialogue. 
Another example, I want to use a tool as a co-researcher or co-writer, I do want it to know what my goals are, my papers (context), mantain history over time, and have interactions both about my research (we discuss aims, goals, implications, interesting directions) and through my research (say we co-write a paper in a shared latex environment). 
Different roles require different levels of dialogue, so this three level distinction is useful to understand what you might need. 
Ok, so how do you enable those levels of dialogue. 
I am not sure. 
Can I answer this already? Maybe. 
At least I know that for full dialogue: you want to mantain history, you want through and about, you want context awareness. 
Weak assymetric: you want consistency, iteration and refinement. 
Pseudodialogue: you want interfaces for generation, exploratory interfaces. 

A general list of design principles would be useful. Can I make a general one? Maybe. 
Each principle is prioritised based on the role and the level of dialogue. 

Can I make a list here of all the roles? Well I just said that this is what I explore in my thesis, so wouldn't that be giving the answer before the question. 

Yeah, but maybe this is a valid thing to do. Write here what you found out and then provide the studies to support it. I have to check other thesis and how they are structured. 

An implication of this analysis is that you an have situations where the intended role by the designer does not match the level of dialogue afforded. We can coin a term for this: role-affordance mismatch. Role-affordance assymetry. Where your tool promises something, that your system will assume a certain role, yet you don't enable the level of dialogue needed. 

Of course this relationship be bidirectional. The interaction enabled, the level of dialogue, determines the role assumed in an emergent manner, and not only that a role determines the level of dialogue expected. Is there evidence for this? 

How do different a priori levels of dialogue determine how people perceive the role of the system? 
I can look at the literature to examine this. For example, did roles changed when people used GPT2 as an autocomplete, vs GPT3 as an instruction follower vs ChatGPT as a chatbot? Probably. Is there evidence for this? Not sure. 

Another hypothesis:
I suspect a pseudolevel of dialogue, is primarily useful enough for divergence roles, whereas a full dialogue more for a convergent role. 
Can a system with full dialogue do the same as one with psedudialogue, therefore, fullfil also a divergent role? Yeah, probably, but perhaps it will be harder and more expensive to design. 

Also, in some cases, maybe you want just to enable divergent exploration, and providing the simplest exploratory interface for this is enough. Providing full dialogic capabilities would add too much cognitive load and make it too complicated for the user. Latent space explorations, and the paper of GAN fashion are good examples. 

## Design principles 

Offer the design principles and table of where in each level they fit. 

## Role classificiation

Identify as series of roles, both from my own studies and from the literature. 
Map them to the levels. 
Map tools to illustrate. 




The contributions of my thesis are: 
I played with a bunch of AI tools
Did a bunch of projects
Read a bunch of papers
And did user studies where I interviewed people using tools I develop to come up with: 

A five level classificiaiton of human-AI co-creativity

Going from the Ai as just a mere generator to a fully embedded cocreator that has access to all your context and workspace and can help you at a very embedded level. For example, a research whose AI has access to its library of papers, research data, previous papers, research question, grants, preferences, style, etc. And a bunch onf others in between. 

With this I also propose a series of design principles for each level. 
Different levels are good fr different things. Depending on the use case and the role the Ai is assuming, or the part of the creative process that its assuming. 

So I map which roles are adequate for each level, based on my case studies, literature and interviews. 

I also map how to design for each level and propose a series of 12 design principles, which can be prioritised by different levels.  

So outcome: 

Five levels of co-creativity
How roles map to those levels
Design principles for each level